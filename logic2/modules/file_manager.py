"""
ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ê´€ë¦¬ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import json
import shutil
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import logging


class FileManager:
    """ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, output_base_path: str = "../output"):
        """
        íŒŒì¼ ê´€ë¦¬ì ì´ˆê¸°í™”
        
        Args:
            output_base_path: ì¶œë ¥ ê¸°ë³¸ ê²½ë¡œ
        """
        self.output_base_path = output_base_path
        self.logger = logging.getLogger(__name__)
        
        # ì¶œë ¥ í´ë” ìƒì„±
        os.makedirs(output_base_path, exist_ok=True)
    
    def create_experiment_output_path(self, scenario_name: str) -> Tuple[str, Dict[str, str]]:
        """
        ì‹¤í—˜ë³„ ê³ ìœ í•œ ì¶œë ¥ í´ë” ë° íŒŒì¼ëª… ìƒì„±
        
        Args:
            scenario_name: ì‹¤í—˜ ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„
            
        Returns:
            Tuple[str, Dict[str, str]]: (ì‹¤í—˜ í´ë” ê²½ë¡œ, íŒŒì¼ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬)
        """
        # í˜„ì¬ ì‹œê°„ (YYYYMMDD_HHMMSS í˜•ì‹)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì‹¤í—˜ í´ë”ëª…: ì‹œë‚˜ë¦¬ì˜¤_ë‚ ì§œì‹œê°„
        experiment_folder = f"{scenario_name}_{timestamp}"
        
        # ì „ì²´ ê²½ë¡œ
        experiment_path = os.path.join(self.output_base_path, experiment_folder)
        
        # í´ë” ìƒì„±
        os.makedirs(experiment_path, exist_ok=True)
        
        # íŒŒì¼ëª… íŒ¨í„´ ìƒì„±
        file_prefix = f"{scenario_name}_{timestamp}"
        
        file_paths = {
            'allocation_results': os.path.join(experiment_path, f"{file_prefix}_allocation_results.csv"),
            'store_summary': os.path.join(experiment_path, f"{file_prefix}_store_summary.csv"),
            'style_analysis': os.path.join(experiment_path, f"{file_prefix}_style_analysis.csv"),
            'top_performers': os.path.join(experiment_path, f"{file_prefix}_top_performers.csv"),
            'scarce_effectiveness': os.path.join(experiment_path, f"{file_prefix}_scarce_effectiveness.csv"),
            'sku_distribution': os.path.join(experiment_path, f"{file_prefix}_sku_distribution.csv"),
            'experiment_params': os.path.join(experiment_path, f"{file_prefix}_experiment_params.json"),
            'experiment_summary': os.path.join(experiment_path, f"{file_prefix}_experiment_summary.txt")
        }
        
        self.logger.info(f"ì‹¤í—˜ ì¶œë ¥ ê²½ë¡œ ìƒì„±: {experiment_path}")
        
        return experiment_path, file_paths
    
    def save_experiment_metadata(self, file_paths: Dict[str, str], scenario_name: str, 
                                params: Dict[str, Any], optimization_result: Dict[str, Any]):
        """
        ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì €ì¥
        
        Args:
            file_paths: íŒŒì¼ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
            scenario_name: ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„
            params: ì‹¤í—˜ íŒŒë¼ë¯¸í„°
            optimization_result: ìµœì í™” ê²°ê³¼
        """
        try:
            # 1. ì‹¤í—˜ íŒŒë¼ë¯¸í„° JSON ì €ì¥
            experiment_info = {
                'scenario_name': scenario_name,
                'timestamp': datetime.now().isoformat(),
                'parameters': params,
                'optimization_status': optimization_result.get('status', 'unknown'),
                'objective_value': optimization_result.get('objective_value', None),
                'total_allocated_items': optimization_result.get('total_allocated_items', 0)
            }
            
            with open(file_paths['experiment_params'], 'w', encoding='utf-8') as f:
                json.dump(experiment_info, f, indent=2, ensure_ascii=False)
            
            # 2. ì‹¤í—˜ ìš”ì•½ í…ìŠ¤íŠ¸ ì €ì¥
            summary_text = self._generate_summary_text(scenario_name, params, optimization_result)
            
            with open(file_paths['experiment_summary'], 'w', encoding='utf-8') as f:
                f.write(summary_text)
            
            self.logger.info(f"ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {scenario_name}")
            
        except Exception as e:
            self.logger.error(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def _generate_summary_text(self, scenario_name: str, params: Dict[str, Any], 
                              optimization_result: Dict[str, Any]) -> str:
        """ì‹¤í—˜ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±"""
        return f"""
========================================
ì‹¤í—˜ ê²°ê³¼ ìš”ì•½
========================================

ì‹¤í—˜ ì‹œë‚˜ë¦¬ì˜¤: {scenario_name}
ì‹¤í—˜ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì„¤ëª…: {params.get('description', 'N/A')}

ğŸ“Š ì‹¤í—˜ íŒŒë¼ë¯¸í„°:
- ì»¤ë²„ë¦¬ì§€ ê°€ì¤‘ì¹˜: {params.get('coverage_weight', 0)}
- ê· í˜• í˜ë„í‹°: {params.get('balance_penalty', 0)}
- ë°°ë¶„ í˜ë„í‹°: {params.get('allocation_penalty', 0)}
- ë°°ë¶„ ë²”ìœ„: {params.get('allocation_range_min', 0)*100:.0f}% ~ {params.get('allocation_range_max', 0)*100:.0f}%
- ìµœì†Œ ì»¤ë²„ë¦¬ì§€: {params.get('min_coverage_threshold', 0)*100:.0f}%

âš¡ ìµœì í™” ê²°ê³¼:
- ìƒíƒœ: {optimization_result.get('status', 'unknown')}
- ëª©ì í•¨ìˆ˜ ê°’: {optimization_result.get('objective_value', 'N/A')}
- ì´ í• ë‹¹ ì•„ì´í…œ: {optimization_result.get('total_allocated_items', 0)}
- ì´ í• ë‹¹ ìˆ˜ëŸ‰: {optimization_result.get('total_allocated_quantity', 0)}
- ì‹¤í–‰ ì‹œê°„: {optimization_result.get('execution_time', 'N/A')}ì´ˆ

ğŸ“ˆ ì„±ê³¼ ë©”íŠ¸ë¦­:
- ì¢…í•© ì ìˆ˜: {optimization_result.get('total_score', 'N/A')}
- ë“±ê¸‰: {optimization_result.get('grade', 'N/A')}
- ìƒ‰ìƒ ì»¤ë²„ë¦¬ì§€: {optimization_result.get('overall_color_coverage', 'N/A')}
- ì‚¬ì´ì¦ˆ ì»¤ë²„ë¦¬ì§€: {optimization_result.get('overall_size_coverage', 'N/A')}
- ë°°ë¶„ íš¨ìœ¨ì„±: {optimization_result.get('overall_allocation_efficiency', 'N/A')}
- ë°°ë¶„ ê· í˜•ì„±: {optimization_result.get('allocation_balance', 'N/A')}

========================================
"""
    
    def save_dataframes(self, file_paths: Dict[str, str], dataframes: Dict[str, pd.DataFrame]):
        """
        DataFrameë“¤ì„ CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            file_paths: íŒŒì¼ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
            dataframes: ì €ì¥í•  DataFrame ë”•ì…”ë„ˆë¦¬
        """
        try:
            saved_files = []
            
            for key, df in dataframes.items():
                if key in file_paths and df is not None and not df.empty:
                    df.to_csv(file_paths[key], index=False, encoding='utf-8-sig')
                    saved_files.append(file_paths[key])
            
            self.logger.info(f"{len(saved_files)}ê°œ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ")
            return saved_files
            
        except Exception as e:
            self.logger.error(f"DataFrame ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def list_experiment_results(self) -> List[Dict[str, Any]]:
        """ì €ì¥ëœ ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ í´ë” ì¡°íšŒ"""
        experiment_folders = []
        
        if not os.path.exists(self.output_base_path):
            return experiment_folders
        
        try:
            for folder in os.listdir(self.output_base_path):
                folder_path = os.path.join(self.output_base_path, folder)
                
                if os.path.isdir(folder_path) and '_' in folder:
                    # í´ë”ëª… íŒ¨í„´: scenario_timestamp
                    parts = folder.split('_')
                    if len(parts) >= 2:
                        try:
                            # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± ê°€ëŠ¥í•œì§€ í™•ì¸
                            timestamp = '_'.join(parts[-2:])  # YYYYMMDD_HHMMSS
                            scenario = '_'.join(parts[:-2])  # ì‹œë‚˜ë¦¬ì˜¤ëª…
                            
                            # ë©”íƒ€ë°ì´í„° íŒŒì¼ í™•ì¸
                            params_file = os.path.join(folder_path, f"{folder}_experiment_params.json")
                            if os.path.exists(params_file):
                                with open(params_file, 'r', encoding='utf-8') as f:
                                    metadata = json.load(f)
                                
                                experiment_folders.append({
                                    'folder_name': folder,
                                    'scenario': scenario,
                                    'timestamp': timestamp,
                                    'status': metadata.get('optimization_status', 'unknown'),
                                    'folder_path': folder_path,
                                    'metadata': metadata
                                })
                        except Exception:
                            continue
            
            # ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹  ìˆœ)
            experiment_folders.sort(key=lambda x: x['timestamp'], reverse=True)
            
        except Exception as e:
            self.logger.error(f"ì‹¤í—˜ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return experiment_folders
    
    def load_experiment_data(self, folder_name: str) -> Optional[Dict[str, Any]]:
        """
        íŠ¹ì • ì‹¤í—˜ì˜ ë°ì´í„°ë¥¼ ë¡œë“œ
        
        Args:
            folder_name: ì‹¤í—˜ í´ë” ì´ë¦„
            
        Returns:
            Optional[Dict[str, Any]]: ì‹¤í—˜ ë°ì´í„° (ë©”íƒ€ë°ì´í„° + DataFrameë“¤)
        """
        folder_path = os.path.join(self.output_base_path, folder_name)
        
        if not os.path.exists(folder_path):
            self.logger.warning(f"ì‹¤í—˜ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_name}")
            return None
        
        try:
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            params_file = os.path.join(folder_path, f"{folder_name}_experiment_params.json")
            with open(params_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # CSV íŒŒì¼ë“¤ ë¡œë“œ
            dataframes = {}
            csv_files = [
                'allocation_results', 'store_summary', 'style_analysis',
                'top_performers', 'scarce_effectiveness', 'sku_distribution'
            ]
            
            for csv_key in csv_files:
                csv_path = os.path.join(folder_path, f"{folder_name}_{csv_key}.csv")
                if os.path.exists(csv_path):
                    dataframes[csv_key] = pd.read_csv(csv_path)
            
            return {
                'metadata': metadata,
                'dataframes': dataframes,
                'folder_path': folder_path
            }
            
        except Exception as e:
            self.logger.error(f"ì‹¤í—˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {folder_name} - {e}")
            return None
    
    def cleanup_old_experiments(self, keep_latest: int = 10) -> int:
        """
        ì˜¤ë˜ëœ ì‹¤í—˜ ê²°ê³¼ ì •ë¦¬ (ìµœì‹  Nê°œë§Œ ìœ ì§€)
        
        Args:
            keep_latest: ìœ ì§€í•  ìµœì‹  ì‹¤í—˜ ìˆ˜
            
        Returns:
            int: ì‚­ì œëœ ì‹¤í—˜ ìˆ˜
        """
        experiments = self.list_experiment_results()
        
        if len(experiments) <= keep_latest:
            self.logger.info(f"ì‹¤í—˜ ê²°ê³¼ê°€ {len(experiments)}ê°œë¡œ ì •ë¦¬ ê¸°ì¤€({keep_latest}ê°œ) ì´í•˜ì…ë‹ˆë‹¤.")
            return 0
        
        # ì˜¤ë˜ëœ ì‹¤í—˜ë“¤ ì„ íƒ
        to_delete = experiments[keep_latest:]
        
        deleted_count = 0
        for exp in to_delete:
            try:
                shutil.rmtree(exp['folder_path'])
                self.logger.info(f"ì‚­ì œ ì™„ë£Œ: {exp['folder_name']}")
                deleted_count += 1
            except Exception as e:
                self.logger.warning(f"ì‚­ì œ ì‹¤íŒ¨: {exp['folder_name']} - {e}")
        
        self.logger.info(f"ì •ë¦¬ ì™„ë£Œ: {deleted_count}ê°œ ì‹¤í—˜ í´ë” ì‚­ì œë¨")
        return deleted_count
    
    def export_experiment_comparison(self, experiment_folders: List[str], 
                                   output_file: str) -> str:
        """
        ì—¬ëŸ¬ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¹„êµ ë¶„ì„í•˜ì—¬ ì—‘ì…€ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
        
        Args:
            experiment_folders: ë¹„êµí•  ì‹¤í—˜ í´ë” ì´ë¦„ ë¦¬ìŠ¤íŠ¸
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            comparison_data = []
            
            for folder_name in experiment_folders:
                experiment_data = self.load_experiment_data(folder_name)
                if experiment_data:
                    metadata = experiment_data['metadata']
                    
                    comparison_data.append({
                        'Experiment': folder_name,
                        'Scenario': metadata.get('scenario_name', ''),
                        'Timestamp': metadata.get('timestamp', ''),
                        'Status': metadata.get('optimization_status', ''),
                        'Objective_Value': metadata.get('objective_value', 0),
                        'Total_Items': metadata.get('total_allocated_items', 0),
                        'Total_Quantity': metadata.get('total_allocated_quantity', 0),
                        'Coverage_Weight': metadata['parameters'].get('coverage_weight', 0),
                        'Balance_Penalty': metadata['parameters'].get('balance_penalty', 0),
                        'Allocation_Penalty': metadata['parameters'].get('allocation_penalty', 0),
                        'Allocation_Range_Min': metadata['parameters'].get('allocation_range_min', 0),
                        'Allocation_Range_Max': metadata['parameters'].get('allocation_range_max', 0),
                        'Min_Coverage_Threshold': metadata['parameters'].get('min_coverage_threshold', 0)
                    })
            
            # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì—‘ì…€ ì €ì¥
            df_comparison = pd.DataFrame(comparison_data)
            
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                df_comparison.to_excel(writer, sheet_name='Experiment_Comparison', index=False)
                
                # ê° ì‹¤í—˜ì˜ ìƒì„¸ ë°ì´í„°ë„ ë³„ë„ ì‹œíŠ¸ë¡œ ì €ì¥
                for folder_name in experiment_folders:
                    experiment_data = self.load_experiment_data(folder_name)
                    if experiment_data and experiment_data['dataframes']:
                        for sheet_name, df in experiment_data['dataframes'].items():
                            if not df.empty:
                                full_sheet_name = f"{folder_name[:10]}_{sheet_name}"[:31]  # ì—‘ì…€ ì‹œíŠ¸ëª… ê¸¸ì´ ì œí•œ
                                df.to_excel(writer, sheet_name=full_sheet_name, index=False)
            
            self.logger.info(f"ì‹¤í—˜ ë¹„êµ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_file}")
            return output_file
            
        except Exception as e:
            self.logger.error(f"ì‹¤í—˜ ë¹„êµ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def get_storage_summary(self) -> Dict[str, Any]:
        """ì €ì¥ì†Œ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        experiments = self.list_experiment_results()
        
        total_size = 0
        scenario_counts = {}
        
        for exp in experiments:
            # í´ë” í¬ê¸° ê³„ì‚°
            folder_size = self._get_folder_size(exp['folder_path'])
            total_size += folder_size
            
            # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¹´ìš´íŠ¸
            scenario = exp['scenario']
            scenario_counts[scenario] = scenario_counts.get(scenario, 0) + 1
        
        return {
            'total_experiments': len(experiments),
            'total_size_mb': total_size / (1024 * 1024),
            'scenario_counts': scenario_counts,
            'latest_experiment': experiments[0] if experiments else None,
            'storage_path': self.output_base_path
        }
    
    def _get_folder_size(self, folder_path: str) -> int:
        """í´ë” í¬ê¸°ë¥¼ ë°”ì´íŠ¸ ë‹¨ìœ„ë¡œ ê³„ì‚°"""
        total_size = 0
        try:
            for dirpath, dirnames, filenames in os.walk(folder_path):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    if os.path.exists(file_path):
                        total_size += os.path.getsize(file_path)
        except Exception:
            pass
        return total_size 